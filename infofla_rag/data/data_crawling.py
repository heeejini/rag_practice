from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from selenium.common.exceptions import TimeoutException, WebDriverException
from urllib3.exceptions import ReadTimeoutError

import sys
import os
import re
import time
import atexit
import json 
class DualLogger:
    def __init__(self, filename: str):
        self._orig_stdout = sys.stdout
        os.makedirs(os.path.dirname(filename) or ".", exist_ok=True)
        self.log = open(filename, "w", encoding="utf-8")
        self._closed = False

    def write(self, message: str):
        try:
            self._orig_stdout.write(message)
        except Exception:
            pass
        if not self._closed and getattr(self, "log", None) and not self.log.closed:
            try:
                self.log.write(message)
            except Exception:
                pass

    def flush(self):
        try:
            self._orig_stdout.flush()
        except Exception:
            pass
        if not self._closed and getattr(self, "log", None) and not self.log.closed:
            try:
                self.log.flush()
            except Exception:
                pass

    def close(self):
        if self._closed:
            return
        self._closed = True
        try:
            if sys.stdout is self:
                sys.stdout = self._orig_stdout
        except Exception:
            pass
        try:
            if getattr(self, "log", None) and not self.log.closed:
                try:
                    self.log.flush()
                except Exception:
                    pass
                self.log.close()
        except Exception:
            pass
        self.log = None


logger = DualLogger("news_output.txt")
sys.stdout = logger
atexit.register(logger.close) 


def slugify(text, maxlen=80):
    text = re.sub(r"\s+", " ", text).strip()
    text = re.sub(r'[\\/:*?"<>|]', "_", text)
    text = text[:maxlen].rstrip("._ ")
    return text or "article"


def setup_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-software-rasterizer")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--window-size=1920,1080")

    options.binary_location = "/usr/bin/chromium-browser"

    driver = webdriver.Chrome(
        service=Service("/usr/bin/chromedriver"),
        options=options,
    )
    return driver



def wait_dom_ready(driver, timeout=15):
    WebDriverWait(driver, timeout).until(
        lambda d: d.execute_script("return document.readyState") in ("interactive", "complete")
    )

def safe_get(driver, url, timeout=30, retries=1, sleep_between=1.0):

    last_err = None
    for attempt in range(retries + 1):
        try:
            driver.set_page_load_timeout(timeout)
            driver.get(url)
            wait_dom_ready(driver, min(12, timeout))
            return True
        except (TimeoutException, ReadTimeoutError, WebDriverException) as e:
            last_err = e
            try:
                driver.execute_script("window.stop();")
            except Exception:
                pass
            if attempt < retries:
                time.sleep(sleep_between)
                continue
            else:
                return False, last_err
    return False, last_err

def extract_body_text(driver, soft_timeout_sec=10):

    t0 = time.time()
    selectors = [
        'div[class*="article-body"]',
        'section[class*="news_view"]',
        'article',
        'div[itemprop="articleBody"]',
        'div[id*="content"]',
        'main'
    ]
    for sel in selectors:
        if time.time() - t0 > soft_timeout_sec:
            break
        try:
            el = driver.find_element(By.CSS_SELECTOR, sel)
            text = el.text.strip()
            if text and len(text) > 60:
                return text
        except Exception:
            continue

    try:
        if time.time() - t0 <= soft_timeout_sec:
            soup = BeautifulSoup(driver.page_source, "html.parser")
            for tag in soup(["script", "style", "noscript"]):
                tag.decompose()
            for sel in ["article", "main", 'div[itemprop="articleBody"]', 'div[id*="content"]', 'section']:
                if time.time() - t0 > soft_timeout_sec:
                    break
                node = soup.select_one(sel)
                if node:
                    txt = node.get_text("\n", strip=True)
                    if txt and len(txt) > 60:
                        return txt
            txt = soup.get_text("\n", strip=True)
            return txt[:5000] if txt else ""
    except Exception:
        pass
    return ""

def main():
    HOME = "https://infofla.com/ko/home"
    SAVE_DIR = "news_articles"
    os.makedirs(SAVE_DIR, exist_ok=True)

    driver = setup_driver()
    wait = WebDriverWait(driver, 15)
    ITEM_MAX_SEC = 40  # ÌïÑÏöîÏãú 60~90ÏúºÎ°ú Ï°∞Ï†ï

    try:
        ok = safe_get(driver, HOME, timeout=25, retries=1)
        if ok is not True:
            success, err = ok  # (False, ÏòàÏô∏)
            print(f"[Ïò§Î•ò] Ìôà Ïù¥Îèô Ïã§Ìå®: {err}")
            return

        title_sel = 'h3[class^="News_articleTitle__"]'
        desc_sel  = 'p[class^="News_articleDescription__"]'
        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, title_sel)))

        titles = driver.find_elements(By.CSS_SELECTOR, title_sel)
        descs  = driver.find_elements(By.CSS_SELECTOR, desc_sel)

        items = []
        for i, t in enumerate(titles):
            try:
                a_tag = t.find_element(By.TAG_NAME, "a")
                title_text = (a_tag.text or "").strip()
                href = a_tag.get_attribute("href") or ""
                link = urljoin(HOME, href) if href else None
                desc_text = (descs[i].text.strip() if i < len(descs) else "")
                if link:
                    items.append({"title": title_text, "desc": desc_text, "link": link})
            except Exception:
                continue

        print(f"[Ï†ïÎ≥¥] ÏàòÏßëÌï† Í∏∞ÏÇ¨ Ïàò: {len(items)}")

        for idx, it in enumerate(items, 1):
            item_start = time.time()
            print(f"\n[{idx}/{len(items)}] üì∞ Ï†úÎ™©: {it['title']}")
            print(f"üí¨ ÏöîÏïΩ: {it['desc']}")
            print(f"üîó ÎßÅÌÅ¨: {it['link']}")

            # ÎÇ®ÏùÄ ÏãúÍ∞ÑÏóê ÎßûÏ∂∞ safe_get ÌÉÄÏûÑÏïÑÏõÉÏùÑ ÎèôÏ†ÅÏúºÎ°ú Ï∂ïÏÜå
            remaining = ITEM_MAX_SEC - (time.time() - item_start)
            if remaining <= 0:
                print("[Ïä§ÌÇµ] ÏïÑÏù¥ÌÖú ÏãúÏûë ÏßÅÌõÑ ÌïòÎìú ÌÉÄÏûÑÏïÑÏõÉ ÏÜåÏßÑ")
                continue

            # ÌéòÏù¥ÏßÄ Î°úÎìú ÌÉÄÏûÑÏïÑÏõÉÏùÄ ÎÇ®ÏùÄ ÏãúÍ∞ÑÏùò 60~70%Î°ú Ï†úÌïú
            nav_timeout = max(8, int(remaining * 0.65))
            ok = safe_get(driver, it["link"], timeout=nav_timeout, retries=1)
            if ok is not True:
                print(f"[Í≤ΩÍ≥†] Î≥∏Î¨∏ ÌéòÏù¥ÏßÄ Ï†ëÏÜç Ïã§Ìå®. ÏõêÏù∏: {ok}")
                # Îã§Ïùå Í∏∞ÏÇ¨Î°ú ÏßÑÌñâÌïòÍ∏∞ Ï†ÑÏóê Ï†ïÎ¶¨
                try:
                    driver.execute_script("window.stop();")
                    driver.get("about:blank")
                except Exception:
                    pass
                continue

            # Î≥∏Î¨∏ Ï∂îÏ∂ú (ÏÜåÌîÑÌä∏ ÌÉÄÏûÑÏïÑÏõÉ: ÎÇ®ÏùÄ ÏãúÍ∞ÑÏùò ÏùºÎ∂Ä)
            remaining = ITEM_MAX_SEC - (time.time() - item_start)
            if remaining <= 0:
                print("[Ïä§ÌÇµ] ÎÑ§ÎπÑÍ≤åÏù¥ÏÖò ÌõÑ ÌïòÎìú ÌÉÄÏûÑÏïÑÏõÉ ÏÜåÏßÑ")
                try:
                    driver.execute_script("window.stop();")
                    driver.get("about:blank")
                except Exception:
                    pass
                continue

            soft_extract = max(5, int(min(12, remaining * 0.6)))
            body = extract_body_text(driver, soft_timeout_sec=soft_extract)

            # ÌïòÎìú ÌÉÄÏûÑÏïÑÏõÉ Ï≤¥ÌÅ¨
            elapsed = time.time() - item_start
            if elapsed > ITEM_MAX_SEC:
                print(f"[Ïä§ÌÇµ] Î≥∏Î¨∏ Ï∂îÏ∂ú Ï§ë ÌïòÎìú ÌÉÄÏûÑÏïÑÏõÉ Ï¥àÍ≥º({elapsed:.1f}s > {ITEM_MAX_SEC}s)")
                try:
                    driver.execute_script("window.stop();")
                    driver.get("about:blank")
                except Exception:
                    pass
                continue

            preview = body[:500] + ("..." if len(body) > 500 else "")
            print(f"‚è± Ï≤òÎ¶¨ÏãúÍ∞Ñ: {elapsed:.1f}s")
            print("üìÑ Î≥∏Î¨∏ ÎØ∏Î¶¨Î≥¥Í∏∞:")
            print(preview if preview else "Î≥∏Î¨∏ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")

            # Ï†ÄÏû•
            fname = f"{slugify(it['title'])}.jsonl"
            fpath = os.path.join(SAVE_DIR, fname)
            record = {
                "title": it["title"],
                "summary": it["desc"],
                "link": it["link"],
                "body": body if body else ""
            }

            with open(fpath, "w", encoding="utf-8") as f:
                f.write(json.dumps(record, ensure_ascii=False) + "\n")

            print(f"üíæ Ï†ÄÏû• ÏôÑÎ£å: {fpath}")
            # Îã§Ïùå Í∏∞ÏÇ¨Ïóê ÏòÅÌñ• ÏóÜÍ≤å Ï†ïÎ¶¨
            try:
                driver.execute_script("window.stop();")
                driver.get("about:blank")
            except Exception:
                pass

    finally:
        try:
            driver.quit()
        except Exception:
            pass
        # ÏïàÏ†Ñ Ï¢ÖÎ£å: stdout ÏõêÎ≥µ ‚Üí ÌååÏùº Îã´Í∏∞
        try:
            if isinstance(sys.stdout, DualLogger):
                sys.stdout.close()
            else:
                try:
                    logger.close()
                except Exception:
                    pass
        except Exception:
            pass


if __name__ == "__main__":
    main()
