from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from selenium.common.exceptions import TimeoutException, WebDriverException
from urllib3.exceptions import ReadTimeoutError

import sys
import os
import re
import time
import atexit

class DualLogger:
    def __init__(self, filename: str):
        self._orig_stdout = sys.stdout
        os.makedirs(os.path.dirname(filename) or ".", exist_ok=True)
        self.log = open(filename, "w", encoding="utf-8")
        self._closed = False

    def write(self, message: str):
        try:
            self._orig_stdout.write(message)
        except Exception:
            pass
        if not self._closed and getattr(self, "log", None) and not self.log.closed:
            try:
                self.log.write(message)
            except Exception:
                pass

    def flush(self):
        try:
            self._orig_stdout.flush()
        except Exception:
            pass
        if not self._closed and getattr(self, "log", None) and not self.log.closed:
            try:
                self.log.flush()
            except Exception:
                pass

    def close(self):
        if self._closed:
            return
        self._closed = True
        try:
            if sys.stdout is self:
                sys.stdout = self._orig_stdout
        except Exception:
            pass
        try:
            if getattr(self, "log", None) and not self.log.closed:
                try:
                    self.log.flush()
                except Exception:
                    pass
                self.log.close()
        except Exception:
            pass
        self.log = None


logger = DualLogger("news_output.txt")
sys.stdout = logger
atexit.register(logger.close) 


def slugify(text, maxlen=80):
    text = re.sub(r"\s+", " ", text).strip()
    text = re.sub(r'[\\/:*?"<>|]', "_", text)
    text = text[:maxlen].rstrip("._ ")
    return text or "article"


def setup_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-software-rasterizer")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--window-size=1920,1080")

    options.binary_location = "/usr/bin/chromium-browser"

    driver = webdriver.Chrome(
        service=Service("/usr/bin/chromedriver"),
        options=options,
    )
    return driver



def wait_dom_ready(driver, timeout=15):
    WebDriverWait(driver, timeout).until(
        lambda d: d.execute_script("return document.readyState") in ("interactive", "complete")
    )

def safe_get(driver, url, timeout=30, retries=1, sleep_between=1.0):

    last_err = None
    for attempt in range(retries + 1):
        try:
            driver.set_page_load_timeout(timeout)
            driver.get(url)
            wait_dom_ready(driver, min(12, timeout))
            return True
        except (TimeoutException, ReadTimeoutError, WebDriverException) as e:
            last_err = e
            try:
                driver.execute_script("window.stop();")
            except Exception:
                pass
            if attempt < retries:
                time.sleep(sleep_between)
                continue
            else:
                return False, last_err
    return False, last_err

def extract_body_text(driver, soft_timeout_sec=10):

    t0 = time.time()
    selectors = [
        'div[class*="article-body"]',
        'section[class*="news_view"]',
        'article',
        'div[itemprop="articleBody"]',
        'div[id*="content"]',
        'main'
    ]
    for sel in selectors:
        if time.time() - t0 > soft_timeout_sec:
            break
        try:
            el = driver.find_element(By.CSS_SELECTOR, sel)
            text = el.text.strip()
            if text and len(text) > 60:
                return text
        except Exception:
            continue

    try:
        if time.time() - t0 <= soft_timeout_sec:
            soup = BeautifulSoup(driver.page_source, "html.parser")
            for tag in soup(["script", "style", "noscript"]):
                tag.decompose()
            for sel in ["article", "main", 'div[itemprop="articleBody"]', 'div[id*="content"]', 'section']:
                if time.time() - t0 > soft_timeout_sec:
                    break
                node = soup.select_one(sel)
                if node:
                    txt = node.get_text("\n", strip=True)
                    if txt and len(txt) > 60:
                        return txt
            txt = soup.get_text("\n", strip=True)
            return txt[:5000] if txt else ""
    except Exception:
        pass
    return ""

def main():
    HOME = "https://infofla.com/ko/home"
    SAVE_DIR = "news_articles"
    os.makedirs(SAVE_DIR, exist_ok=True)

    driver = setup_driver()
    wait = WebDriverWait(driver, 15)
    ITEM_MAX_SEC = 40  # í•„ìš”ì‹œ 60~90ìœ¼ë¡œ ì¡°ì •

    try:
        ok = safe_get(driver, HOME, timeout=25, retries=1)
        if ok is not True:
            success, err = ok  # (False, ì˜ˆì™¸)
            print(f"[ì˜¤ë¥˜] í™ˆ ì´ë™ ì‹¤íŒ¨: {err}")
            return

        title_sel = 'h3[class^="News_articleTitle__"]'
        desc_sel  = 'p[class^="News_articleDescription__"]'
        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, title_sel)))

        titles = driver.find_elements(By.CSS_SELECTOR, title_sel)
        descs  = driver.find_elements(By.CSS_SELECTOR, desc_sel)

        items = []
        for i, t in enumerate(titles):
            try:
                a_tag = t.find_element(By.TAG_NAME, "a")
                title_text = (a_tag.text or "").strip()
                href = a_tag.get_attribute("href") or ""
                link = urljoin(HOME, href) if href else None
                desc_text = (descs[i].text.strip() if i < len(descs) else "")
                if link:
                    items.append({"title": title_text, "desc": desc_text, "link": link})
            except Exception:
                continue

        print(f"[ì •ë³´] ìˆ˜ì§‘í•  ê¸°ì‚¬ ìˆ˜: {len(items)}")

        for idx, it in enumerate(items, 1):
            item_start = time.time()
            print(f"\n[{idx}/{len(items)}] ğŸ“° ì œëª©: {it['title']}")
            print(f"ğŸ’¬ ìš”ì•½: {it['desc']}")
            print(f"ğŸ”— ë§í¬: {it['link']}")

            # ë‚¨ì€ ì‹œê°„ì— ë§ì¶° safe_get íƒ€ì„ì•„ì›ƒì„ ë™ì ìœ¼ë¡œ ì¶•ì†Œ
            remaining = ITEM_MAX_SEC - (time.time() - item_start)
            if remaining <= 0:
                print("[ìŠ¤í‚µ] ì•„ì´í…œ ì‹œì‘ ì§í›„ í•˜ë“œ íƒ€ì„ì•„ì›ƒ ì†Œì§„")
                continue

            # í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒì€ ë‚¨ì€ ì‹œê°„ì˜ 60~70%ë¡œ ì œí•œ
            nav_timeout = max(8, int(remaining * 0.65))
            ok = safe_get(driver, it["link"], timeout=nav_timeout, retries=1)
            if ok is not True:
                print(f"[ê²½ê³ ] ë³¸ë¬¸ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨. ì›ì¸: {ok}")
                # ë‹¤ìŒ ê¸°ì‚¬ë¡œ ì§„í–‰í•˜ê¸° ì „ì— ì •ë¦¬
                try:
                    driver.execute_script("window.stop();")
                    driver.get("about:blank")
                except Exception:
                    pass
                continue

            # ë³¸ë¬¸ ì¶”ì¶œ (ì†Œí”„íŠ¸ íƒ€ì„ì•„ì›ƒ: ë‚¨ì€ ì‹œê°„ì˜ ì¼ë¶€)
            remaining = ITEM_MAX_SEC - (time.time() - item_start)
            if remaining <= 0:
                print("[ìŠ¤í‚µ] ë„¤ë¹„ê²Œì´ì…˜ í›„ í•˜ë“œ íƒ€ì„ì•„ì›ƒ ì†Œì§„")
                try:
                    driver.execute_script("window.stop();")
                    driver.get("about:blank")
                except Exception:
                    pass
                continue

            soft_extract = max(5, int(min(12, remaining * 0.6)))
            body = extract_body_text(driver, soft_timeout_sec=soft_extract)

            # í•˜ë“œ íƒ€ì„ì•„ì›ƒ ì²´í¬
            elapsed = time.time() - item_start
            if elapsed > ITEM_MAX_SEC:
                print(f"[ìŠ¤í‚µ] ë³¸ë¬¸ ì¶”ì¶œ ì¤‘ í•˜ë“œ íƒ€ì„ì•„ì›ƒ ì´ˆê³¼({elapsed:.1f}s > {ITEM_MAX_SEC}s)")
                try:
                    driver.execute_script("window.stop();")
                    driver.get("about:blank")
                except Exception:
                    pass
                continue

            preview = body[:500] + ("..." if len(body) > 500 else "")
            print(f"â± ì²˜ë¦¬ì‹œê°„: {elapsed:.1f}s")
            print("ğŸ“„ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°:")
            print(preview if preview else "ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ì €ì¥
            fname = f"{slugify(it['title'])}.txt"
            fpath = os.path.join(SAVE_DIR, fname)
            with open(fpath, "w", encoding="utf-8") as f:
                f.write(f"ì œëª©: {it['title']}\n")
                f.write(f"ìš”ì•½: {it['desc']}\n")
                f.write(f"ë§í¬: {it['link']}\n\n")
                f.write("ë³¸ë¬¸:\n")
                f.write(body if body else "ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {fpath}")

            # ë‹¤ìŒ ê¸°ì‚¬ì— ì˜í–¥ ì—†ê²Œ ì •ë¦¬
            try:
                driver.execute_script("window.stop();")
                driver.get("about:blank")
            except Exception:
                pass

    finally:
        try:
            driver.quit()
        except Exception:
            pass
        # ì•ˆì „ ì¢…ë£Œ: stdout ì›ë³µ â†’ íŒŒì¼ ë‹«ê¸°
        try:
            if isinstance(sys.stdout, DualLogger):
                sys.stdout.close()
            else:
                try:
                    logger.close()
                except Exception:
                    pass
        except Exception:
            pass


if __name__ == "__main__":
    main()
